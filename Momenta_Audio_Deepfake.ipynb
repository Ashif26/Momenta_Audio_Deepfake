{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1/aAoPENtkU4IsCrc8WYR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashif26/Momenta_Audio_Deepfake/blob/main/Momenta_Audio_Deepfake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Research & Selection\n",
        "\n",
        "### 1️⃣ Model Name (e.g., RawNet2)\n",
        "- **Innovation**: Uses raw waveform input instead of spectrograms.\n",
        "- **Performance**: Achieves 90%+ accuracy on ASVspoof dataset.\n",
        "- **Why It's Promising**: Works well for real-time applications.\n",
        "- **Challenges**: Needs more training for new attack types.\n",
        "\n",
        "### 2️⃣ Model Name (e.g., Wav2Vec2)\n",
        "- **Innovation**: Self-supervised learning with large-scale speech data.\n",
        "- **Performance**: Detects subtle deepfake audio manipulations.\n",
        "- **Why It's Promising**: Can generalize across datasets.\n",
        "- **Challenges**: Requires significant compute power.\n",
        "\n",
        "### 3️⃣ Model Name (e.g., ResNet-based CNN)\n",
        "- **Innovation**: Deep convolutional layers extract audio forgeries.\n",
        "- **Performance**: Strong results on multiple datasets.\n",
        "- **Why It's Promising**: Works well with short speech samples.\n",
        "- **Challenges**: Computational cost is high for real-time use.\n"
      ],
      "metadata": {
        "id": "_OjF_PtbrA9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wget https://zenodo.org/record/14498691/files/ASVspoof2019_LA_train.zip\n",
        "!unzip ASVspoof2019_LA_train.zip\n"
      ],
      "metadata": {
        "id": "TJOTpAEnswzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load an audio file\n",
        "audio_path = \"path_to_audio_file.wav\"\n",
        "y, sr = librosa.load(audio_path, sr=16000)\n",
        "\n",
        "# Compute Mel spectrogram\n",
        "mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "# Display spectrogram\n",
        "plt.figure(figsize=(10, 4))\n",
        "librosa.display.specshow(mel_spec_db, sr=sr, x_axis=\"time\", y_axis=\"mel\")\n",
        "plt.colorbar(format=\"%+2.0f dB\")\n",
        "plt.title(\"Mel Spectrogram\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jIdshnoas26X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install torch torchaudio\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "from torchaudio.models import wav2vec2_base\n",
        "\n",
        "# Load pretrained model\n",
        "model = wav2vec2_base()\n",
        "\n",
        "# Pass an audio sample through the model\n",
        "waveform, sample_rate = torchaudio.load(\"path_to_audio_file.wav\")\n",
        "output = model(waveform)\n",
        "\n",
        "print(output.shape)  # Output features\n"
      ],
      "metadata": {
        "id": "S9daG9nYs99J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "y_true = [0, 1, 0, 1]  # Actual labels (0: real, 1: fake)\n",
        "y_pred = [0, 1, 1, 1]  # Model predictions\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n"
      ],
      "metadata": {
        "id": "N70AKs73s-9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"deepfake_model.pth\")\n"
      ],
      "metadata": {
        "id": "Hq5dorIMtEvM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}